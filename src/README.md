# Resume and Video Processing Pipeline

## Overview
This pipeline processes both a resume PDF and an interview video in parallel. It uses AI to extract and analyze text from the resume and performs detailed audio analysis from the video, including extracting features such as speech rate, average volume, sentiment, and pauses.

## Features
- **Resume Text Extraction**: Extracts text from a PDF resume and processes it using OpenAI to create a structured CV.
- **Audio Extraction**: Extracts audio from video files and saves it as a `.wav` file.
- **Audio Feature Extraction**:
  - Dynamic silence detection based on energy levels in the audio.
  - Computes speech rate (words per minute).
  - Calculates average audio volume.
  - Detects sentiment in the transcribed audio text.
- **Parallel Processing**: Uses Python's `ThreadPoolExecutor` to process resume and video tasks concurrently.

## Key Functions
### ResumeProcessor
- `extract_text_from_pdf()`: Extracts text from the PDF file.
- `process_resume_with_ai()`: Sends extracted text to OpenAI to generate structured resume content.

### VideoProcessor
- `extract_audio_from_video()`: Extracts audio from the video file and saves it as `.wav`.
- `compute_energy_db()`: Computes the energy of the audio signal in decibels.
- `compute_dynamic_threshold()`: Calculates a dynamic threshold for detecting silence.
- `extract_non_silence_frames()`: Identifies non-silence segments in the audio.
- `process_silence_segments()`: Separates silence and non-silence audio segments.
- `transcribe_audio()`: Transcribes the audio into text using Whisper.
- `compute_speech_rate()`: Calculates the speech rate in words per minute.
- `compute_average_volume()`: Computes the average volume (RMS) of the audio.
- `sentiment_analysis()`: Analyzes the sentiment of the transcribed text.

### ResumeVideoPipeline
- `run_pipeline()`: Runs the resume and video processing tasks in parallel.
- `process_resume_pipeline()`: Extracts text and processes it using AI.
- `process_video_pipeline()`: Extracts and processes the video/audio features.

## Notable Decisions
- **Resume Processing via OpenAi GPT**: OpenAI's GPT service is used to create structured resumes from the content of the raw ones.
- **Dynamic Thresholding for Silence**: The audio silence detection is dynamically adjusted based on the energy levels of the audio, making it adaptive to varying noise levels.
- **Parallel Processing**: The pipeline handles resume and video processing in parallel, which improves efficiency for long-running tasks.
- **Whisper Transcription**: Whisper's transcription service is used to convert audio to text for further analysis.

## Usage
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
1. Install `ffmpeg`: Read the file `install_ffmpeg` and follow the instructions. 

   

2. Set up environment variables in a `.env` file with your OpenAI API key:
   ```plaintext
   API_KEY=your_openai_api_key
   ```

3. Run the pipeline:
   ```python
   from src.resume_interview_analyzer import ResumeVideoPipeline
   
   resume_pdf = "path_to_resume.pdf"
   video_file = "path_to_video.mp4"
   
   pipeline = ResumeVideoPipeline(resume_pdf, video_file)
   results = pipeline.run_pipeline()
   
   print(results)
   ```

## Output
The pipeline will return:
- **Structured Resume**: Processed resume content generated by OpenAI LLM.
- **Audio Features**: A dictionary containing pause count, total pause duration, speech rate, average volume, and sentiment from the video interview.

## Contribution
Don't hesitate to create some issues for helping me fixing the bugs you encounter.